import pandas, pickle, traceback, sys
from lib.log import log, notify, progress
from lib.repo import Loader, Searcher

r, U = False, 1.0
for A in sys.argv[1:]:
  A = A.lower().strip()

  if A == 'reindex': r = True
  if A.startswith('frac='):
    try: U = float(A[5:])
    except: pass

try:

  log('âœ¨', U, r)
  notify('ğŸ”´')

  S = Searcher()
  if r:

    M = [(k, L.melt(k)) for L in [
      Loader.Within("api.uprp.gov.pl"),
      Loader.Within("api.lens.org"),
      Loader.Within("api.openalex.org")
    ] for k in ['date', 'number', 'name', 'city', 'title']]

    S.iterload(progress(M, desc='ğŸ“‘'))
    with open('searcher.pkl', 'wb') as f:
      pickle.dump(S.snapshot, f)
      log('ğŸ’¾')

  else:
    with open('searcher.pkl', 'rb') as f:
      S.snapload(pickle.load(f))
      log('ğŸ“‚')

  notify('ğŸŸ¡')

  Q = pandas.read_csv('raport.uprp.gov.pl.csv').reset_index()\
  .rename(columns={'docs':'query', 'index':'entry'})[['entry', 'query']]\
  .drop_duplicates(subset=['query'], keep='first')
  if U != 1.0: Q = Q.sample(frac=U, random_state=0)
  log('ğŸ—³', U)

  notify('ğŸŸ¢')
  Y = S.multisearch(progress(Q.itertuples(index=False), desc='ğŸ”', total=Q.shape[0]))
  with open(f'matches{U if U != 1.0 else ""}.pkl', 'wb') as f:
    pickle.dump(Y, f)

  log('âœ…')
  notify('ğŸ')

except Exception as e:
  log('âŒ', e)
  log(traceback.format_exc())
  notify("âŒ")