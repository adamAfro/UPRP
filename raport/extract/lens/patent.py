# Pobieranie danych dot. patent贸w z lens.org
# ==========================================
from pandas import read_csv, DataFrame
from tqdm import tqdm as progress; progress.pandas()
import requests, json, datetime, os, time

# Funkcja API do pobierania przyjmuje kody patentowe pod
# ustalon jurysdykcja - oznaczana przez dwuliterowy kod.
# Zapytania i dane s zapisywane w formacie JSON do p贸藕niejszych
# analiz.
def API(j:str, N:list, t='puttokenhere'):
  
  q = f'{{ "size": 100, "query": "(jurisdiction:{j}) AND ({" OR ".join(["(doc_number:"+n+")" for n in N])})" }}'
  h = {'Authorization': f'Bearer {t}', 'Content-Type': 'application/json'}
  u = 'https://api.lens.org/patent/search'
  y = requests.post(u, data=q, headers=h)
  if y.status_code != 200: raise Exception(f'Error {y.status_code} {y.text}')    
  t = datetime.datetime.now().strftime('%Y-%m-%d-%H:%M:%S')
  with open(f'res/{t}.json', 'w') as f: f.write(y.text)
  with open(f'req/{t}.json', 'w') as f: 
    f.write(json.dumps({ "jurisdiction": j, "doc_number": N }))
  return json.loads(y.text)

# Do pobrania patent贸w wystarczajace s ich same kody.
X = read_csv("../patent.csv", dtype=str)[["country", "number", "sufix"]]\
 .drop_duplicates(subset=["country", "number"]).dropna()

# Pominicie patent贸w USA
# -----------------------
# Urzd patentowy USA oferuje swoje dane od 2001 roku, oraz
# caociowe w postaci og贸lnodostpnych plik贸w. Z tego powodu
# s pomijane w zapytaniach.
# Z podobnych wzgld贸w mog by pomijane inne kraje,
# co do kt贸rych brak pewnoci o isteniniu takiej bazy (CN, JP).
X = X.query('~country.str.startswith("US")')
X = X.query('~country.str.startswith("CN")')
X = X.query('~country.str.startswith("JP")')


# Odfiltrowanie patent贸w polskich
# --------------------------------
#
# Ze wzgldu na to, 偶e polskie patenty s dostpne w
# bazie UPRP to s pomijane w 偶daniach.
X = X.query('~country.str.startswith("PL")')

# Wyb贸r zbior贸w
# -------------
#
# Ze wzgldu na liczno zbior贸w, wybierane s tylko
# te, kt贸re maj wicej ni偶 1000 patent贸w. Inne zbiory mog
# by bdne, albo i nie. W ka偶dym razie ich liczno jest
# argumentem przeciw temu, dlatego na wstpie s poimjane.
c = X['country'].value_counts().to_frame()
c.query('1000<=count').plot.barh()
c.query('100<=count<1000').plot.barh()
c.query('10<=count<100').plot.barh()
c.query('1<=count<10').plot.barh()
X = X.query('country in @c.query("1000<=count").index')

# Ograniczenia API
# ---------------
#
# Lens.org zazwyczaj zwraca zazwyczaj wicej ni偶 100 wynik贸w,
# a ograniczenie zwrotne zapytania to wanie 100.
# Z tego powodu, p贸藕niej nale偶y jeszcze raz przetestowa, czy
# pr贸by pobrania wizay si z pora偶k z powodu limitu API,
# czy braku danych.

# Pobrane dane
# ------------
#
# Przed pobieraniem trzeba sprawdzi co zostao ju偶 pobrane,
# i co w og贸le byo poddane pr贸bie pobierania. Po filtracji
# pobierana jest reszta, dziki temu oszczdzane s ograniczone
# zasoby API.
# Czasami jest wiele znajd dla pojedynczego kodu, bo s r贸偶ne
# rodzaje dokument贸w. Dodanie jednak typu dokumentu, kt贸ry nie
# zawsze jest obecny albo poprawny wi偶e si z problemem braku
# znajd wanie z tych powod贸w.
#
# Niekt贸re patenty s pominiete z powod贸w wymienionych wczeniej.
# Majc odpowiedzi z pierwszej iteracji, kt贸re maj
# liczno `result` wiksz/r贸wn caoci `total` wiadomo, 
# 偶e obecne w niej nieznajdy s poprawnie nieobecne.
# Jeli jest `results < total`, wtedy nale偶y powt贸rnie 
# pobiera dane, bo `results < 100`.
Q = []
for f0 in os.listdir('req'):
  with open(f'req/{f0}') as f: q = json.load(f)
  if f0.endswith('0-res.json'):
    for n in q['doc_number']:
      Q.append({ "country": q['jurisdiction'], "number": n, "matches": 0 })
    continue
  with open(f'res/{f0}') as f: R = json.load(f)
  for n in q['doc_number']:
    k = sum([1 for d in R['data'] if (n == d['doc_number'])
              and (q['jurisdiction'] == d['jurisdiction'])])
    if (k == 0) and ((R.get('results', 0) == 0) or (R['results'] < R['total'])): continue
    Q.append({ "country": q['jurisdiction'], "number": n, "matches": k })
Q = DataFrame(Q)
Q['matches'].value_counts().sort_index()\
  .plot.bar(title='Wyszukiwane kody patentowe', 
            ylabel="ilo wyszukiwanych kod贸w patentowych",
            xlabel="ilo dopasowa")

# Wczeniejsze bdy doporwadziy do nieporawnych duplikat贸w,
# kt贸re nale偶y usun.
Q = Q.sort_values('matches', ascending=False).drop_duplicates(keep='first')

X = X.merge(Q, on=['country', 'number'], how='left')
X['matches'].fillna(-1).astype(int).astype(str).replace("-1", "N/A")\
  .value_counts().sort_index()\
  .plot.bar(title='Wyniki zapyta API',
            ylabel="ilo wyszukiwanych kod贸w patentowych",
            xlabel="ilo dopasowa");

X0 = X
X = X.query('matches.isnull()').drop('matches', axis=1)

# Pobieranie patent贸w
# -------------------
# Ograniczenie pobierania do `k` ze wzgldu na limity API:
# limit `k` powinien zapewni w wikszosci przypadk贸w margines
# na ewentualne nadmiarowe pobrania, a dziki temu mo偶na p贸藕niej
# okreli, czy jakie inne dane zostay pominite. Ustalenie
# `k` opiera si o proste obliczenia - automatycznie d偶y do 
# zachowania 100 rekord贸w w odpowiedziach na podst. wcz. zap.
#
# Dodadkowe kroki:
#
# * wybranie arbitralnie odpowiedniej dugoci kod贸w patentowych:
# r贸偶ne kraje maj r贸偶ne dugoci, a por贸d nich jest wiele odstpstw;
# * ustalenie jurysdykcji.
for c in X0['country'].value_counts().sort_values(ascending=True).index:
  for l in X0.query('country == @c')['number'].str.len().value_counts()\
    .sort_values(ascending=False).index:
    
    C = X.query('(country == @c) and (number.str.len() == @l)')
    print(c, l, f'{Q[Q["country"] == c].shape[0]} ')
    dt = 60/10 # maks. 10 zap. na min.
    if C.shape[0] < 75: continue
    with progress(total=C.shape[0]) as p:
      i, n, m5 = 0, 75, [100, 100, 100]
      while i < C.shape[0]:
        t0 = time.time()
        B = C.iloc[i:i+n]
        R = API(c, [v for v in B['number'].values])
        dt0 = time.time() - t0
        if dt0 < dt: time.sleep(dt - dt0 + 0.1)

        p.update(n)
        i += n

        if R.get('results', 0) == 0:
          print('')
          with open(f'req/{datetime.datetime.now().strftime("%Y-%m-%d-%H:%M:%S")}-0-res.json', 'w') as f: 
            f.write(json.dumps({ "jurisdiction": c, "doc_number": [n for n in C['number']] }))
          break
        m5 = [m5[1], m5[2], R['results']]
        n = int(n + (95 - sum(m5)/len(m5))//5)
        p.set_postfix({'n': n, 'total': R['total'], 'results': R['results'] })
        